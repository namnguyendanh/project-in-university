{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from underthesea import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def segmentation(lines):\n",
    "    lines = word_tokenize(lines)\n",
    "    new_line = ''\n",
    "    for word in lines:\n",
    "        if ' ' in word:\n",
    "            tokens = word.split()\n",
    "            word = '_'.join(tokens)\n",
    "        new_line += word + ' '\n",
    "    return new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    list_folders = os.listdir(path)\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    for i, name_folder in enumerate(list_folders):\n",
    "        tag = i\n",
    "        path_folder = path + '/' + name_folder\n",
    "        list_file = os.listdir(path_folder)\n",
    "        count = 0\n",
    "        for file in list_file:\n",
    "            if count == 1000:\n",
    "                break\n",
    "            else:\n",
    "                file_name = path_folder + '/' + file\n",
    "                f = open(file_name, 'r', encoding='utf-16')\n",
    "                lines = f.readlines()\n",
    "                lines = ' '.join(lines)\n",
    "                new_line = segmentation(lines)\n",
    "                new_line = simple_preprocess(new_line)\n",
    "                new_line = ' '.join(new_line)\n",
    "                count += 1\n",
    "                sentences.append(new_line)\n",
    "                labels.append(i)\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = load_data('10Topics/Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doanh_nhân muốn thể_hiện cả tài lẫn tâm tối_qua nhân ngày doanh_nhân việt_nam các doanh_nghiệp khu_vực phía nam đã có buổi gặp_gỡ tại khách_sạn sheraton quận tp hcm để giao_lưu chia_sẻ kinh_nghiệm quý_báu trong kinh_doanh thông_qua cuộc gặp_gỡ này doanh giới đã quyên_góp được tỷ đồng vào quỹ hoạt_động xã_hội trong số tiền tỷ đồng có triệu đồng dành cho quỹ góp tay xoa_dịu nỗi đau da_cam triệu đồng dùng để xây_dựng căn nhà tình_thương triệu đồng còn lại dành cho quỹ đặt tượng ông phạm_hảo_hớn chủ_tịch hiệp_hội doanh_nghiệp tp hcm cho rằng không chỉ là ngày vui của doanh_nghiệp cả nước mà chính là ngày của tất_cả những ai có tâm hướng khởi_nghiệp do_đó ngoài hoa và lời chúc_tụng doanh giới còn phải tự nhắc nhau phải làm gì để xứng_đáng với sự tôn_vinh của xã_hội doanh_nghiệp có trách_nhiệm xây_dựng cho được những thương_hiệu việt có_mặt trên toàn thế_giới nghĩa_là phải tạo_dựng được một nền văn_hóa kinh_doanh ngang tầm với trọng_trách đã lãnh nhận bí_quyết thành_công của nhà_kinh_doanh là trung_thực nghĩa_là nguồn lợi thu về phải theo lẽ tự_nhiên không vì lợi_ích mà làm điều xằng_bậy người_ta giàu nghèo tâm đức lòng ngay_thẳng khoan_hậu với người đây cũng là phép_thuật kinh_doanh vậy ông hớn nói thêm cũng trong chương_trình ngày doanh_nhân việt_nam diễn ra tối_qua tại hà_nội huế và tp hcm thuộc tập_đoàn pg một tập_đoàn vốn tư_nhân trong nước chính_thức tuyên_bố ủng_hộ cho người nghèo với số tiền lên tới tỷ đồng tiền này sẽ được giải_ngân trong năm liên_tiếp nhằm hưởng_ứng chương_trình vì người nghèo do mặt_trận phát_động theo dự_kiến ban_đầu trong tổng_số tiền tỷ đồng này pg_richfarm sẽ trao tỷ đồng tiền_mặt cho chương_trình hỗ_trợ người nghèo của tỉnh trong các hoạt_động từ_thiện trực_tiếp còn lại sẽ được sử_dụng để truyền_thông tăng_cường tri_thức làm_giàu bằng nông_nghiệp chuyển_giao kỹ_thuật chăn_nuôi và kinh_doanh chăn_nuôi tiên_tiến cho nông_dân nghèo các tỉnh'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8755"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_pred == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
