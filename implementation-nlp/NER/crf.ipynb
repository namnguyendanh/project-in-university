{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import sklearn\n",
    "import sklearn_crfsuite\n",
    "import string\n",
    "\n",
    "def isName(word):\n",
    "    if ' ' in word:\n",
    "        broken = word.split(' ')\n",
    "        for i in range(len(broken)):\n",
    "            if broken[i].islower():\n",
    "                return False\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def isMixCase(word):\n",
    "    if len(word) > 2:\n",
    "        if word[0].islower() and word[1].istitle():\n",
    "            return True\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "def wordShape(word):\n",
    "    shape = ''\n",
    "    for character in word:\n",
    "        if character.istitle():\n",
    "            shape += 'U'\n",
    "        elif character.islower():\n",
    "            shape += 'L'\n",
    "        elif character.isdigit():\n",
    "            shape += 'D'\n",
    "        else:\n",
    "            shape += character\n",
    "    return shape\n",
    "\n",
    "def parse_file(file_name):\n",
    "    f = open(file_name, 'r')\n",
    "    sentences = []\n",
    "    sent = []\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            tokens = line.strip().split('\\t')\n",
    "            if len(tokens) == 4:\n",
    "                token = tokens[0]\n",
    "                pos = tokens[1]\n",
    "                chunk = tokens[2]\n",
    "                label = tokens[-1]\n",
    "                sent.append((token, pos, chunk, label))\n",
    "        else:\n",
    "            sentences.append(sent)\n",
    "            sent = []\n",
    "    return sentences\n",
    "\n",
    "def word2feature(sent, i):\n",
    "    word = sent[i][0]\n",
    "    if word in string.punctuation:\n",
    "        word = '<punct>'\n",
    "    if word[0].isdigit():\n",
    "        word = '<number>'\n",
    "    pos = sent[i][1]\n",
    "    chunk = sent[i][2]\n",
    "    features = {\n",
    "        'w(0)': word,\n",
    "        'w(0)[:1]': word[:1],\n",
    "        'w(0)[:2]': word[:2],\n",
    "        'w(0)[:3]': word[:3],\n",
    "        'w(0)[:4]': word[:4],\n",
    "        'w(0)[-1:]': word[-1:],\n",
    "        'w(0)[-2:]': word[-2:],\n",
    "        'w(0)[-3:]': word[-3:],\n",
    "        'w(0)[-4:]': word[-4:],\n",
    "        'word.islower':word.islower(),\n",
    "        'word.lower': word.lower(),\n",
    "        'isTitle': word[0].istitle(),\n",
    "        'isNumber': word.isdigit(),\n",
    "        'isUpper': word.isupper(),\n",
    "        'isCapWithPeriod': word[0].istitle() and word[-1] == '.',\n",
    "        'endsInDigit': word[-1].isdigit(),\n",
    "        'containHyphen': '-' in word,\n",
    "        'isDate': word[0].isdigit() and word[-1].isdigit() and '/' in word,\n",
    "        'isCode': word[0].isdigit() and word[-1].istitle(),\n",
    "        'isName': isName(word),\n",
    "        'isMixCase': isMixCase(word),\n",
    "        'd&comma': word[0].isdigit() and word[-1].isdigit() and ',' in word,\n",
    "        'd&period': word[0].isdigit() and word[-1].isdigit() and '.' in word,\n",
    "        'wordShape': wordShape(word),\n",
    "        \n",
    "        'pos(0)': pos,\n",
    "        'chunk(0)': chunk\n",
    "    }\n",
    "    if ' ' in word:\n",
    "        for idx, _ in enumerate(word.split(' ')):\n",
    "            features.update({\n",
    "                '{}thword'.format(idx): word.split(' ')[idx]\n",
    "            })\n",
    "    if (i > 0):\n",
    "        prev_word = sent[i-1][0]\n",
    "        if prev_word in string.punctuation:\n",
    "            prev_word = '<punct>'\n",
    "        if prev_word[0].isdigit():\n",
    "            prev_word = '<number>'\n",
    "        prev_pos = sent[i-1][1]\n",
    "        prev_chunk = sent[i-1][2]\n",
    "        features.update({\n",
    "            'w(-1)': prev_word,\n",
    "            'w(-1).lower':prev_word.lower(),\n",
    "            'isTitle(-1)': prev_word[0].istitle(),\n",
    "            'isNumber(-1)': prev_word.isdigit(),\n",
    "            'isCapWithPeriod(-1)': prev_word[0].istitle() and prev_word[-1] == '.',\n",
    "            'isName(-1)': isName(prev_word),\n",
    "            'wordShape(-1)': wordShape(prev_word),\n",
    "            'w(-1)+w(0)': prev_word + ' ' + word,\n",
    "            \n",
    "            'pos(-1)': prev_pos,\n",
    "            'chunk(-1)': prev_chunk,\n",
    "            'pos(-1) + pos(0)': prev_pos + ' ' + pos,\n",
    "            'chunk(-1) + chunk(0)': prev_chunk + ' ' + chunk\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    \n",
    "    if i > 1:\n",
    "        prev_2_word = sent[i-2][0]\n",
    "        if prev_2_word in string.punctuation:\n",
    "            prev_2_word = '<punction>'\n",
    "        if prev_2_word[0].isdigit():\n",
    "            prev_2_word = '<number>'\n",
    "        prev_2_pos = sent[i-2][1]\n",
    "        prev_2_chunk = sent[i-2][2]\n",
    "        features.update({\n",
    "            'w(-2)': prev_2_word,\n",
    "            'w(-2)+w(-1)': prev_2_word + ' ' + prev_word,\n",
    "            'w(-2).isTitle()': prev_2_word[0].istitle(),\n",
    "            'w(-2).isdigit': prev_2_word[0].isdigit(),\n",
    "            \n",
    "            'pos(-2)': prev_2_pos,\n",
    "            'chunk(-2)': prev_2_chunk,\n",
    "            'pos(-2) + pos(-1)': prev_2_pos + ' ' + prev_pos,\n",
    "            'chunk(-2) + chunk(-1)': prev_2_chunk + ' ' + prev_chunk\n",
    "        })\n",
    "    if i < (len(sent) - 1):\n",
    "        next_word = sent[i+1][0]\n",
    "        if next_word in string.punctuation:\n",
    "            next_word = '<punct>'\n",
    "        if next_word[0].isdigit():\n",
    "            next_word = '<number>'\n",
    "        next_pos = sent[i+1][1]\n",
    "        next_chunk = sent[i+1][2]\n",
    "        features.update({\n",
    "            'w(1)': next_word,\n",
    "            'w(1).lower': next_word.lower(),\n",
    "            'isTitle(1)': next_word[0].istitle(),\n",
    "            'isNumber(1)': next_word.isdigit(),\n",
    "            'isCapWithPeriod(1)': next_word[0].istitle() and next_word[-1] == '.',\n",
    "            'isName(1)': isName(next_word),\n",
    "            'wordShape(1)': wordShape(next_word),\n",
    "            'w(0)+w(1)': word + ' ' + next_word,\n",
    "            \n",
    "            'pos(1)': next_pos,\n",
    "            'chunk(1)': next_chunk,\n",
    "            'pos(0)+pos(1)': pos + ' ' + next_pos,\n",
    "            'chunk(0)+chunk(1)': chunk +' '+ next_chunk,\n",
    "        })\n",
    "    \n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "    if i < (len(sent) - 2):\n",
    "        next_2_word = sent[i+2][0]\n",
    "        if next_2_word in string.punctuation:\n",
    "            next_2_word = '<punct>'\n",
    "        if next_2_word[0].isdigit():\n",
    "            next_2_word = '<number>'\n",
    "        next_2_pos = sent[i+2][1]\n",
    "        next_2_chunk = sent[i+2][2]\n",
    "        features.update({\n",
    "            'w(2)': next_2_word,\n",
    "            'w(1) + w(2)': word + ' ' + next_word,\n",
    "            'w(2).isTitle()': next_2_word[0].istitle(),\n",
    "            'w(2).isdigit': next_2_word[0].isdigit(),\n",
    "            \n",
    "            'pos(2)': next_2_pos,\n",
    "            'chunk(2)': next_2_chunk,\n",
    "            'pos(1) + pos(2)': next_pos + ' ' + next_2_pos,\n",
    "            'chunk(1) + chunk(2)': next_2_chunk\n",
    "        })\n",
    "    return features\n",
    "\n",
    "def get_features(sent):\n",
    "    return [word2feature(sent, i) for i in range(len(sent))]\n",
    "def get_labels(sent):\n",
    "    return [label for token, _, _, label in sent]\n",
    "def get_tokens(sent):\n",
    "    return [token for token, _, _, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent = parse_file('vlsp2016/train.txt')\n",
    "test_sent = parse_file('vlsp2016/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [get_features(s) for s in train_sent]\n",
    "y_train = [get_labels(s) for s in train_sent]\n",
    "X_test = [get_features(s) for s in test_sent]\n",
    "y_test = [get_labels(s) for s in test_sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm = 'lbfgs',\n",
    "    c1 = 0.06,\n",
    "    c2 = 0.1,\n",
    "    max_iterations = 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf.fit(X_train, y_train)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'trained_model.pkl'\n",
    "pickle.dump(crf, open(file_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9290437013731012"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC      0.919     0.936     0.927      1376\n",
      "       I-LOC      0.904     0.933     0.918       463\n",
      "      B-MISC      1.000     0.878     0.935        49\n",
      "      I-MISC      1.000     0.878     0.935        49\n",
      "       B-ORG      0.865     0.653     0.744       274\n",
      "       I-ORG      0.944     0.899     0.921       397\n",
      "       B-PER      0.934     0.944     0.939      1294\n",
      "       I-PER      0.975     0.981     0.978       983\n",
      "\n",
      "   micro avg      0.934     0.927     0.930      4885\n",
      "   macro avg      0.942     0.888     0.912      4885\n",
      "weighted avg      0.933     0.927     0.929      4885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
